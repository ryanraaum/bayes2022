---
title: "Projection Predictive Varible Selection"
author: "Ryan Raaum - Spring 2022"
course: "Introduction to Bayesian Statistics"
output:
  rrmdstyle::html_worksheet: default
  rrmdstyle::pdf_worksheet: default
---

## Setup 

You'll need to install some packages and install the github version of `brms`.

```{r setup-new-packages}
if (packageVersion("brms") == '2.16.3') install.packages("paul-buerkner/brms")
if (!(require("TH.data", quietly = TRUE))) install.packages("TH.data")
if (!(require("projpred", quietly = TRUE))) install.packages("projpred")
```

As always, load up the packages that we need.

```{r setup-packages, message=FALSE}
library(TH.data) # for the variable selection dataset
library(ggplot2) # plotting
theme_set(theme_minimal()) # not necessary, I just don't like the default ggplot theme
library(brms) # for Bayesian modeling
library(bayesplot) # for plotting of Bayesian models
library(dplyr) # for data wrangling
library(posterior) # for working with posterior distributions
library(projpred) # projected prediction variable selection
```

# Variable Selection

For the variable selection example, you will use a series of measurements from a laser scanning image of the eye for individuals with and without glaucoma. There are 62 potential predictors and one outcome variable (`Class`).

```{r data-pre-processing}
data("GlaucomaM", package = "TH.data")

# for the logistic regression we're going to do, this factor needs to be
# numeric. Now "1" will be glaucoma and "0" is no glaucoma
GlaucomaM <- GlaucomaM %>% 
  mutate(Class = as.numeric(Class) - 1)

target <- "Class"
predictors <- names(GlaucomaM)[1:62]

# want to standardize the predictors
GlaucomaM[,predictors] <- scale(GlaucomaM[,predictors])
```

We'll build the reference model formula programatically instead of writing it out.

```{r make-forumula}
formula1 <- formula(paste("Class ~", paste(predictors, collapse=" + ")))
formula1
```

```{r build-reference-model}
CHAINS = 4
CORES = 2
SEED = 12345

# parameterize horseshoe prior
p <- length(predictors) # number of predictors
n <- nrow(GlaucomaM) # number of observations
p0 <- 15 # guess for the number of relevant variables
tau0 <- p0/(p-p0) * 1/sqrt(n)

fit1 <- brm(formula1,
            data = GlaucomaM,
            family = bernoulli,
            prior = prior(horseshoe(scale_global = tau0), class=b),
            control = list(adapt_delta = 0.9), # take this out
            seed = SEED, chains = CHAINS, cores = CORES)
```

There might be a divergent transition when you first run the code above. If so, you should fix that by changing the `adapt_delta` value. The default value for `adapt_delta` for `brms` is 0.8, which is quite low compared to the `rstanarm` default value of 0.95. The full argument to add to change the value is `control = list(adapt_delta = <VALUE>)`.

Once you have a model fit without transitions, we can look at the posterior. In the lecture, I did density plots (`mcmc_areas`), but with 62 predictors that gets all scrunched up and very difficult to look at, so here I've done interval plots flipped sideways instead. It's still not the easiest thing to look at, but it's better.

```{r visualize-posterior}
pd1 <- as_draws_array(fit1)
mcmc_intervals(pd1[,,paste0("b_", predictors)], inner_size=1, point_size=1) + 
  coord_flip() + # easier to fit a lot on the plot flipped
  guides(x = guide_axis(angle = 90)) # make the labels readable
```

So - while there are a lot of the predictors whose posterior distributions are clumped up around zero, there are a couple that are clearly non-zero and several others that might not be. So, let's do the variable selection. First, we create the reference model object.

```{r extract-refmodel}
refmodel <- get_refmodel(fit1)
```

Now, we can do the varible selection using the `vs_varsel` function. This will take a little while to run...(took about 7 minutes on my nothing-special office desktop).

```{r do-variable-selection}
vs1 <- cv_varsel(fit1)
```

Now we can visualize the submodel ELPDs relative to the reference model (`deltas = TRUE`).

```{r plot-vs-2}
plot(vs1, deltas = TRUE)
```

And determine how many variables the procedure deems useful as predictors.

```{r suggest-size}
n_selected <- suggest_size(vs1)
n_selected
```

And figure out which ones those are.

```{r variables-selected}
v_selected <- solution_terms(vs1)[1:n_selected]
v_selected
```

We can project the posterior distribution of the selected variables.

```{r project-submodel, fig.height=3}
# generate the projection for our selected variables
projection1 <- project(vs1, nterms=n_selected, ndraws = 1000)
# convert that to something that we can plot with bayesplot
projpd1 <- as.matrix(projection1)   
# and visualize
mcmc_areas(projpd1, pars = v_selected)
```

```{r compare-projection-reference}
pd1 <- as.matrix(refmodel$fit)
ref_p <- mcmc_intervals(pd1, pars=paste0("b_", v_selected)) + xlim(-3,3)
proj_p <- mcmc_intervals(projpd1, pars = v_selected) + xlim(-3,3)
ref_p / proj_p
```

```{r refit-selected-vars}
refit_formula <- formula(paste("Class ~ ", paste(v_selected, collapse=" + ")))

refit <- brm(formula1,
            data = GlaucomaM,
            family = bernoulli,
            prior = prior(normal(0, 0.5), class=b),
            save_pars = save_pars(all = TRUE),
            seed = SEED, chains = CHAINS, cores = CORES)
```

```{r refit-posterior}
refitpd <- as_draws_array(refit)
mcmc_areas(refitpd, pars=paste0("b_", v_selected))
```

```{r refit-loo}
refitloo <- loo(refit, moment_match = TRUE, save_psis = TRUE)
```

```{r baseline-model}
fit0 <- update(refit, formula = Class ~ 1, refresh=0)
fit0loo <- loo(fit0)
loo_compare(fit0loo, refitloo)
```

```{r}
linpred <- posterior_linpred(refit)
preds <- posterior_epred(refit)
pred <- colMeans(preds)
pr <- as.integer(pred >= 0.5)
y <- GlaucomaM$Class

# posterior classification accuracy
round(mean(xor(pr,as.integer(y==0))),2)

# posterior balanced classification accuracy
round((mean(xor(pr[y==0]>0.5,as.integer(y[y==0])))+mean(xor(pr[y==1]<0.5,as.integer(y[y==1]))))/2,2)

# LOO predictive probabilities
ploo=E_loo(preds, refitloo$psis_object, type="mean", log_ratios = -log_lik(refit))$value
# LOO classification accuracy
round(mean(xor(ploo>0.5,as.integer(y==0))),2)

# LOO balanced classification accuracy
round((mean(xor(ploo[y==0]>0.5,as.integer(y[y==0])))+mean(xor(ploo[y==1]<0.5,as.integer(y[y==1]))))/2,2)

qplot(pred, ploo)
```

```{r}
calPlotData<-calibration(factor(y) ~ pred + loopred, 
                         data = data.frame(pred=pred,loopred=ploo,y=y), 
                         cuts=10, class="1")
ggplot(calPlotData, auto.key = list(columns = 2))+
  scale_colour_brewer(palette = "Set1")
```

```{r}
library(splines)
library(MASS)
ggplot(data = data.frame(pred=pred,loopred=ploo,y=y), aes(x=loopred, y=y)) +
  stat_smooth(method='glm', formula = y ~ ns(x, 5), fullrange=TRUE) +
  geom_abline(linetype = 'dashed') +
  labs(x = "Predicted (LOO)", y = "Observed") +
  geom_jitter(height=0.02, width=0, alpha=0.3) +
  scale_y_continuous(breaks=seq(0,1,by=0.1)) +
  xlim(c(0,1))
```


```{r refmodel-dens-overlay}
refitppd <- posterior_predict(refit)
#
#
y <- GlaucomaM$Class
ppc_bars(y, refitppd)
ppc_ecdf_overlay(y, refitppd[1:50,])
ppc_rootogram(y, refitppd)
```

See: https://avehtari.github.io/modelselection/diabetes.html

