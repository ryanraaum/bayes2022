---
title: "Projection Predictive Variable Selection"
author: "Ryan Raaum - Spring 2022"
course: "Introduction to Bayesian Statistics"
output:
  rrmdstyle::html_worksheet: default
  rrmdstyle::pdf_worksheet: default
---

## Setup 

You'll need to install some packages and install the github version of `brms`.

```{r setup-new-packages}
if (packageVersion("brms") == '2.16.3') install.packages("paul-buerkner/brms")
if (!(require("TH.data", quietly = TRUE))) install.packages("TH.data")
if (!(require("projpred", quietly = TRUE))) install.packages("projpred")
```

As always, load up the packages that we need.

```{r setup-packages, message=FALSE}
library(TH.data) # for the variable selection dataset
library(ggplot2) # plotting
library(patchwork) # for laying out plots
theme_set(theme_minimal()) # not necessary, I just don't like the default ggplot theme
library(brms) # for Bayesian modeling
library(bayesplot) # for plotting of Bayesian models
library(dplyr) # for data wrangling
library(posterior) # for working with posterior distributions
library(projpred) # projected prediction variable selection
```

# Variable Selection

For the variable selection example, you will use a series of measurements from a laser scanning image of the eye for individuals with and without glaucoma. There are 62 potential predictors and one outcome variable (`Class`).

```{r data-pre-processing}
data("GlaucomaM", package = "TH.data")

# for the logistic regression we're going to do, this factor needs to be
# numeric. Now "1" will be glaucoma and "0" is no glaucoma
GlaucomaM <- GlaucomaM %>% 
  mutate(Class = as.numeric(Class) - 1)

target <- "Class"
predictors <- names(GlaucomaM)[1:62]

# want to standardize the predictors
GlaucomaM[,predictors] <- scale(GlaucomaM[,predictors])
```

We'll build the reference model formula programatically instead of writing it out.

```{r make-forumula}
formula1 <- formula(paste("Class ~", paste(predictors, collapse=" + ")))
formula1
```

```{r build-reference-model}
CHAINS = 4
CORES = parallel::detectCores() - 1
SEED = 12345

# parameterize horseshoe prior
p <- length(predictors) # number of predictors
n <- nrow(GlaucomaM) # number of observations
p0 <- 15 # guess for the number of relevant variables
tau0 <- p0/(p-p0) * 1/sqrt(n)

fit1 <- brm(formula1,
            data = GlaucomaM,
            family = bernoulli,
            prior = prior(horseshoe(scale_global = tau0), class=b),
            seed = SEED, chains = CHAINS, cores = CORES)
```

There might be a divergent transition when you first run the code above. If so, you should fix that by changing the `adapt_delta` value. The default value for `adapt_delta` for `brms` is 0.8, which is quite low compared to the `rstanarm` default value of 0.95. The full argument to add to change the value is `control = list(adapt_delta = <VALUE>)`.

Once you have a model fit without transitions, we can look at the posterior. In the lecture, I did density plots (`mcmc_areas`), but with 62 predictors that gets all scrunched up and very difficult to look at, so here I've done interval plots flipped sideways instead. It's still not the easiest thing to look at, but it's better.

```{r visualize-posterior}
pd1 <- as_draws_array(fit1)
mcmc_intervals(pd1[,,paste0("b_", predictors)], inner_size=1, point_size=1) + 
  coord_flip() + # easier to fit a lot on the plot flipped
  guides(x = guide_axis(angle = 90)) # make the labels readable
```

So - while there are a lot of the predictors whose posterior distributions are clumped up around zero, there are a couple that are clearly non-zero and several others that might not be. So, let's do the variable selection. 

Next we can look at the posterior predictive distribution. For logistic regression - where there are only two possible outcomes (here 0 and 1) - there aren't a lot of options for posterior predictive plots. Most don't really look like much of anything. The best that I've come up with is to look at the mean of the outcome variable (which is equal to the proportion of 1's). So, we'll generate some posterior predictive samples and plot out the distribution of their means compared to the observed data.

```{r post-pred}
post1 <- posterior_predict(fit1)
ppc_stat(GlaucomaM$Class, post1, mean, binwidth=0.01) # bit of trial and error to find a good number
```

Your results may vary (as there's some randomness here), but this looks generally ok to me (although it does seem that most of the time that there is a slight bias to both slight over- and under-estimation of the proportion of 1's).

For the variable selection, we first create the reference model object.

```{r extract-refmodel}
refmodel <- get_refmodel(fit1)
```

Now, we can do the variable selection using the `vs_varsel` function. This will take a little while to run...(took about 7 minutes on my nothing-special office desktop). There will be a warning about some Pareto k values being too high (there's one and it's not an issue here).

```{r do-variable-selection}
vs1 <- cv_varsel(fit1)
```

Now we can visualize the submodel ELPDs relative to the reference model (`deltas = TRUE`).

```{r plot-vs-2}
plot(vs1, deltas = TRUE)
```

And determine how many variables the procedure deems useful as predictors.

```{r suggest-size}
n_selected <- suggest_size(vs1)
n_selected
```

And figure out which ones those are.

```{r variables-selected}
v_selected <- solution_terms(vs1)[1:n_selected]
v_selected
```

We can project the posterior distribution of the selected variables and visualize.

```{r project-submodel, fig.height=3}
# generate the projection for our selected variables
projection1 <- project(vs1, nterms=n_selected, ndraws = 1000)
# convert that to something that we can plot with bayesplot
projpd1 <- as.matrix(projection1)   
# and visualize
mcmc_areas(projpd1, pars = v_selected)
```

And compare these to the posterior distributions for these variables in the reference model.

```{r compare-projection-reference}
ref_p <- mcmc_areas(pd1, pars=paste0("b_", v_selected)) + xlim(-3,3)
proj_p <- mcmc_areas(projpd1, pars = v_selected) + xlim(-3,3)
ref_p + proj_p
```

How do the projections compare to a new fit using those variables?

```{r refit-selected-vars}
refit_formula <- formula(paste("Class ~ ", paste(v_selected, collapse=" + ")))

refit <- brm(formula1,
            data = GlaucomaM,
            family = bernoulli,
            prior = prior(normal(0, 0.5), class=b),
            save_pars = save_pars(all = TRUE), 
            seed = SEED, chains = CHAINS, cores = CORES)
```

We can now look at the refit posterior distribution (left) vs the projected posterior (right).

```{r refit-posterior}
refitpd <- as_draws_array(refit)
mcmc_areas(refitpd, pars=paste0("b_", v_selected)) + proj_p
```

Finally, we can look at the posterior predictive distribution for the refit submodel and compare that to the observed values.

```{r refit-post-pred}
refitpost <- posterior_predict(refit)
ppc_stat(GlaucomaM$Class, refitpost, mean, binwidth=0.01)
```

Which looks pretty much like what we saw for the full model.
